<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Addressing Outliers For Resilient Machine Learning Models | Outlier Blog</title><meta name=keywords content="data-cleaning,data-analysis"><meta name=description content="Imagine you’ve spent months collecting and preparing your dataset, carefully selecting features, and building a machine learning model. You’ve fine-tuned the hyperparameters, evaluated the model’s performance, and you’re feeling confident that it’s ready to make accurate predictions on new data. But as soon as you deploy the model, you start to notice some strange results. The model is making bizarre predictions that don’t seem to make sense. What went wrong? The answer may lie in outliers — those pesky data points that can wreak havoc on machine learning models."><meta name=author content="Thomas Shaw"><link rel=canonical href=https://outlierblog.me/posts/addressing_outlier/><meta name=google-site-verification content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.bf5f9f73cf17311d52cedbcda82c922e91b2f566d88a85ad9f5b5a08b586bd5f.css integrity="sha256-v1+fc88XMR1SztvNqCySLpGy9WbYioWtn1taCLWGvV8=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.acb54fd32bbc1982428b8850317e45d076b95012730a5936667e6bc21777692a.js integrity="sha256-rLVP0yu8GYJCi4hQMX5F0Ha5UBJzClk2Zn5rwhd3aSo=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://outlierblog.me/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://outlierblog.me/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://outlierblog.me/favicon-32x32.png><link rel=apple-touch-icon href=https://outlierblog.me/apple-touch-icon.png><link rel=mask-icon href=https://outlierblog.me/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.7/dist/katex.min.css integrity=sha384-3UiQGuEI4TTMaFmGIZumfRPtfKQ3trwQE2JgosJxCnGmQpL/lJdjpcHkaaFwHlcI crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.7/dist/katex.min.js integrity=sha384-G0zcxDFp5LWZtDuRMnBkk3EphCK1lhEf4UEyEM693ka574TZGwo4IWwS6QLzM/2t crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.7/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous onload='renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"\\[",right:"\\]",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1}]})'></script>
<link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css integrity=sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js integrity=sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4 crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js integrity=sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa crossorigin=anonymous onload=renderMathInElement(document.body)></script>
<script async src="https://www.googletagmanager.com/gtag/js?id=G-018FG8S7HC"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-018FG8S7HC",{anonymize_ip:!1})}</script><meta property="og:title" content="Addressing Outliers For Resilient Machine Learning Models"><meta property="og:description" content="Imagine you’ve spent months collecting and preparing your dataset, carefully selecting features, and building a machine learning model. You’ve fine-tuned the hyperparameters, evaluated the model’s performance, and you’re feeling confident that it’s ready to make accurate predictions on new data. But as soon as you deploy the model, you start to notice some strange results. The model is making bizarre predictions that don’t seem to make sense. What went wrong? The answer may lie in outliers — those pesky data points that can wreak havoc on machine learning models."><meta property="og:type" content="article"><meta property="og:url" content="https://outlierblog.me/posts/addressing_outlier/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-05-29T11:30:14+08:00"><meta property="article:modified_time" content="2023-05-29T11:30:14+08:00"><meta property="og:site_name" content="Outlier Blog"><meta name=twitter:card content="summary"><meta name=twitter:title content="Addressing Outliers For Resilient Machine Learning Models"><meta name=twitter:description content="Imagine you’ve spent months collecting and preparing your dataset, carefully selecting features, and building a machine learning model. You’ve fine-tuned the hyperparameters, evaluated the model’s performance, and you’re feeling confident that it’s ready to make accurate predictions on new data. But as soon as you deploy the model, you start to notice some strange results. The model is making bizarre predictions that don’t seem to make sense. What went wrong? The answer may lie in outliers — those pesky data points that can wreak havoc on machine learning models."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://outlierblog.me/posts/"},{"@type":"ListItem","position":2,"name":"Addressing Outliers For Resilient Machine Learning Models","item":"https://outlierblog.me/posts/addressing_outlier/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Addressing Outliers For Resilient Machine Learning Models","name":"Addressing Outliers For Resilient Machine Learning Models","description":"Imagine you’ve spent months collecting and preparing your dataset, carefully selecting features, and building a machine learning model. You’ve fine-tuned the hyperparameters, evaluated the model’s performance, and you’re feeling confident that it’s ready to make accurate predictions on new data. But as soon as you deploy the model, you start to notice some strange results. The model is making bizarre predictions that don’t seem to make sense. What went wrong? The answer may lie in outliers — those pesky data points that can wreak havoc on machine learning models.","keywords":["data-cleaning","data-analysis"],"articleBody":"Imagine you’ve spent months collecting and preparing your dataset, carefully selecting features, and building a machine learning model. You’ve fine-tuned the hyperparameters, evaluated the model’s performance, and you’re feeling confident that it’s ready to make accurate predictions on new data. But as soon as you deploy the model, you start to notice some strange results. The model is making bizarre predictions that don’t seem to make sense. What went wrong? The answer may lie in outliers — those pesky data points that can wreak havoc on machine learning models. In this blog post, we’ll explore the impact of outliers on machine learning models and discuss various strategies for detecting them to build more resilient models.\nUnderstanding Outliers Outliers are values within a dataset that vary greatly from the others, either much larger or significantly smaller. These values can be caused by measurement errors, data entry errors, or even legitimate extreme values.\nOutliers have the potential to impact machine learning models in several ways. One of the most significant ways outliers affect the models is by distorting the distribution of the data. As outliers do not follow the same pattern as the other data points, they can significantly change the mean, median, and standard deviation of a dataset. This can lead to misleading or inaccurate representations of the data, resulting in flawed models.\nOutliers can also affect the fit of the machine learning model. When outliers are present in the dataset, they can have a disproportionate impact on the model’s coefficients. This can lead to an overfit or underfit model, where the model is too complex or too simple, respectively. Such models are unlikely to make accurate predictions, leading to poor performance. Therefore, it is essential to detect and address outliers to ensure the machine learning models are accurate and reliable. Addressing outliers is an essential step in building resilient machine learning models.\nThe Various Causes of Outliers in Datasets 1. Data Entry Errors: One of the main causes of outliers is data entry errors. These errors can occur due to typos or decimal point errors, which can lead to incorrect data being recorded. In some cases, data may also be recorded twice or entered into the wrong field, leading to an outlier in the dataset.\n2. Measurement Errors: Another common cause of outliers is measurement errors. These can occur due to faulty instruments, inaccurate readings, or human error. For example, if a scale is not calibrated properly, it may record weights that are significantly different from the actual weight.\n3. Sampling Errors: Outliers can also occur due to sampling errors, which can happen when the sample size is too small or the sampling method is biased. For example, if a survey only includes respondents from a specific demographic, it may not accurately reflect the opinions or behaviors of the larger population.\n4. Legitimate Extreme Values: Outliers can also be legitimate extreme values that are important to capture. For instance, in a study of the income distribution, billionaires would be considered outliers, but their inclusion would be necessary to accurately reflect the distribution of wealth.\n5. Natural Variation: Finally, outliers can occur due to natural variations in the data. In some cases, the presence of outliers can indicate that the data is not normally distributed. This can be useful information for data analysis as it can help identify potential issues with the data.\nTypes of Outliers There are generally two types of outliers: univariate outliers and multivariate outliers. Univariate outliers are observations that have extreme values that relate to just a single variable. These outliers can be identified by examining the distribution of a single variable using methods such as box plots or histograms. For example, in a dataset of students’ test scores, a student who scored significantly higher or lower than the other students would be considered a univariate outlier.\nMultivariate outliers, on the other hand, are observations that have extreme values for a combination of variables. These outliers can be more challenging to detect than univariate outliers, as they may not be apparent when examining each variable individually. Multivariate outliers can be identified by using methods such as principal component analysis or cluster analysis. For example, in a dataset of patients’ medical records, a patient who has a combination of extreme values for several health indicators (such as blood pressure, heart rate, and cholesterol levels) may be considered a multivariate outlier.\nHow to Identify Outliers There are various ways to identify outliers in a dataset using visualization and statistical methods. Here’s an example in Python using a toy dataset:\nFirst, let’s import the necessary libraries and create the dataset:\nimport pandas as pd import numpy as np import seaborn as sns from scipy import stats # create toy dataset with outliers data = {'x': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25], 'y': [8, 6, 9, 7, 15, 6, 7, 10, 12, 6, 7, 8, 9, 6, 7, 8, 100, 12, 10, 6, 7, 8, 9, 6, 7]} df = pd.DataFrame(data)  Identifying outliers using visualization 1. Box plot One common way to identify outliers is by using box plots. Box plots provide a visual representation of the distribution of the data, and can highlight observations that are significantly different from the others.\n# detect outliers using boxplot sns.boxplot(df)  From the box plot, we can see that there are some outliers in the y column, but none in the x column.\n2. Scatter plot Another way to identify outliers is by using scatter plots. By plotting the relationship between two variables, scatter plots can effectively illustrate any observations that deviate significantly from the others.\n# detect outliers using scatterplot sns.scatterplot(x=df['x'], y=df['y'])  From the scatter plot, we can see that there is one observation with x value of 17 and y value of 100 that is significantly different from the others.\nIdentifying outliers using statistical methods 1. Interquartile range (IQR) The IQR (interquartile range) method is a statistical technique used to identify and handle outliers in a dataset. The IQR is defined as the difference between the third quartile (75th percentile) and the first quartile (25th percentile) of the data.\nTo use the IQR method to identify outliers, we can follow these steps:\n Calculate the IQR: IQR = Q3 - Q1 Determine the lower bound: Q1 - 1.5 * IQR Determine the upper bound: Q3 + 1.5 * IQR Identify the outliers: Any data point that falls outside the lower or upper bound is considered an outlier.  The IQR method is effective in identifying outliers that are more extreme than those identified by the z-score method. It is less sensitive to extreme values than the z-score method and therefore less likely to flag values as outliers that are actually valid data points. However, it can still misidentify valid data points as outliers if the distribution of the data is highly skewed.\n# detect outliers using IQR Q1 = df['y'].quantile(0.25) Q3 = df['y'].quantile(0.75) IQR = Q3 - Q1 outliers = df[(df['y'] Q3 + 1.5 * IQR)] print(outliers)  2. Z-score The z-score method is a statistical technique used to identify outliers based on their deviation from the mean. It measures how many standard deviations an observation is away from the mean.\nThe formula for calculating the z-score for a particular observation is:\n$$ z = {(x - \\mu) \\over \\sigma} $$\nwhere x is the value of the observation, μ is the mean of the dataset, and σ is the standard deviation of the dataset.\nIf the absolute value of the z-score is greater than a certain threshold, typically 3 or 2.5, then the observation is considered an outlier.\n# detect outliers using z-score z_scores = np.abs(stats.zscore(df['y'])) threshold = 3 outliers = df[z_scores  threshold] print(outliers)  The z-score method is widely used in various fields, including finance, economics, and engineering, as it provides a standardized way of identifying extreme values in a dataset. However, it may not always be appropriate to use this method, especially if the dataset is not normally distributed or if there are only a few observations.\nWhen Should Outliers Be Removed The decision of whether to remove outliers from a dataset depends on the context and purpose of the analysis. In some cases, outliers may be genuine observations that are important and should not be removed. In other cases, outliers may be errors or anomalies that can distort the analysis and should be removed.\nHere are some general guidelines for when outliers should be removed:\n1. Outliers are errors or anomalies: If outliers are due to data collection or measurement errors, they should be removed as they do not represent the true population. For example, a weight measurement of 2000 pounds for a human being is an outlier and should be removed because it is physically impossible. Similarly, if data is manually entered and there are typos or errors, those values should be removed.\n2. Outliers are not representative of the population: Outliers that are not representative of the population being studied may be removed if they skew the distribution or analysis of the data. For instance, if a study is investigating the incomes of middle-class households, an extremely high income that is not representative of the middle class may be removed. Similarly, if a study is investigating the height of adult males, a female value may be an outlier and should be removed. Removing these outliers can help to achieve a more accurate representation of the population.\n3. Outliers significantly affect the results: Outliers that significantly affect the results of an analysis may be removed if they are deemed to be distorting the data. For example, in regression analysis, outliers can have a disproportionate influence on the regression line and can skew the overall fit of the model. In this case, removing the outliers can help to achieve a more accurate and representative model. However, it is important to note that removing too many outliers can lead to an oversimplification of the model and can lead to the loss of important information.\nTakeaways  Outliers are values within a dataset that vary greatly from the others, either much larger or significantly smaller, and can be caused by measurement errors, data entry errors, or even legitimate extreme values. Outliers can impact machine learning models by distorting the data distribution, affecting the fit of the model, and resulting in inaccurate predictions. There are generally two types of outliers: univariate and multivariate. Univariate outliers are observations that have extreme values that relate to just one variable. Multivariate outliers are observations that have extreme values for a combination of variables. There are various ways to identify outliers, including visualization (e.g., box plots, scatter plots) and statistical methods (e.g., IQR, z-score). The decision of whether to remove outliers from a dataset depends on the context and purpose of the analysis, and outliers should only be removed after careful consideration to ensure that the resulting model accurately represents the population being studied.  ","wordCount":"1843","inLanguage":"en","datePublished":"2023-05-29T11:30:14+08:00","dateModified":"2023-05-29T11:30:14+08:00","author":{"@type":"Person","name":"Thomas Shaw"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://outlierblog.me/posts/addressing_outlier/"},"publisher":{"@type":"Organization","name":"Outlier Blog","logo":{"@type":"ImageObject","url":"https://outlierblog.me/favicon.ico"}}}</script></head><body class=dark id=top><script>localStorage.getItem("pref-theme")==="light"&&document.body.classList.remove("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://outlierblog.me/ accesskey=h title="Outlier Blog (Alt + H)"><img src=https://outlierblog.me/apple-touch-icon.png alt aria-label=logo height=35>Outlier Blog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://outlierblog.me/ title=Home><span>Home</span></a></li><li><a href=https://outlierblog.me/series/ title=Series><span>Series</span></a></li><li><a href=https://outlierblog.me/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://outlierblog.me/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class=post-title>Addressing Outliers For Resilient Machine Learning Models</h1><div class=post-meta><span title="2023-05-29 11:30:14 +0800 +08">May 29, 2023</span>&nbsp;·&nbsp;9 min&nbsp;·&nbsp;Thomas Shaw</div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#understanding-outliers>Understanding Outliers</a></li><li><a href=#the-various-causes-of-outliers-in-datasets>The Various Causes of Outliers in Datasets</a></li><li><a href=#types-of-outliers>Types of Outliers</a></li><li><a href=#how-to-identify-outliers>How to Identify Outliers</a><ul><li><a href=#identifying-outliers-using-visualization>Identifying outliers using visualization</a></li><li><a href=#2-scatter-plot>2. Scatter plot</a></li><li><a href=#identifying-outliers-using-statistical-methods>Identifying outliers using statistical methods</a></li></ul></li><li><a href=#when-should-outliers-be-removed>When Should Outliers Be Removed</a><ul><li><a href=#takeaways>Takeaways</a></li></ul></li></ul></nav></div></details></div><div class=post-content><p>Imagine you’ve spent months collecting and preparing your dataset, carefully selecting features, and building a machine learning model. You’ve fine-tuned the hyperparameters, evaluated the model’s performance, and you’re feeling confident that it’s ready to make accurate predictions on new data. But as soon as you deploy the model, you start to notice some strange results. The model is making bizarre predictions that don’t seem to make sense. What went wrong? The answer may lie in outliers — those pesky data points that can wreak havoc on machine learning models. In this blog post, we’ll explore the impact of outliers on machine learning models and discuss various strategies for detecting them to build more resilient models.</p><h2 id=understanding-outliers>Understanding Outliers</h2><p>Outliers are values within a dataset that vary greatly from the others, either much larger or significantly smaller. These values can be caused by measurement errors, data entry errors, or even legitimate extreme values.</p><p>Outliers have the potential to impact machine learning models in several ways. One of the most significant ways outliers affect the models is by distorting the distribution of the data. As outliers do not follow the same pattern as the other data points, they can significantly change the mean, median, and standard deviation of a dataset. This can lead to misleading or inaccurate representations of the data, resulting in flawed models.</p><p>Outliers can also affect the fit of the machine learning model. When outliers are present in the dataset, they can have a disproportionate impact on the model&rsquo;s coefficients. This can lead to an overfit or underfit model, where the model is too complex or too simple, respectively. Such models are unlikely to make accurate predictions, leading to poor performance. Therefore, it is essential to detect and address outliers to ensure the machine learning models are accurate and reliable. Addressing outliers is an essential step in building resilient machine learning models.</p><h2 id=the-various-causes-of-outliers-in-datasets>The Various Causes of Outliers in Datasets</h2><p><strong>1. Data Entry Errors:</strong> One of the main causes of outliers is data entry errors. These errors can occur due to typos or decimal point errors, which can lead to incorrect data being recorded. In some cases, data may also be recorded twice or entered into the wrong field, leading to an outlier in the dataset.</p><p><strong>2. Measurement Errors:</strong> Another common cause of outliers is measurement errors. These can occur due to faulty instruments, inaccurate readings, or human error. For example, if a scale is not calibrated properly, it may record weights that are significantly different from the actual weight.</p><p><strong>3. Sampling Errors:</strong> Outliers can also occur due to sampling errors, which can happen when the sample size is too small or the sampling method is biased. For example, if a survey only includes respondents from a specific demographic, it may not accurately reflect the opinions or behaviors of the larger population.</p><p><strong>4. Legitimate Extreme Values:</strong> Outliers can also be legitimate extreme values that are important to capture. For instance, in a study of the income distribution, billionaires would be considered outliers, but their inclusion would be necessary to accurately reflect the distribution of wealth.</p><p><strong>5. Natural Variation:</strong> Finally, outliers can occur due to natural variations in the data. In some cases, the presence of outliers can indicate that the data is not normally distributed. This can be useful information for data analysis as it can help identify potential issues with the data.</p><h2 id=types-of-outliers>Types of Outliers</h2><p>There are generally two types of outliers: univariate outliers and multivariate outliers. Univariate outliers are observations that have extreme values that relate to just a single variable. These outliers can be identified by examining the distribution of a single variable using methods such as box plots or histograms. For example, in a dataset of students&rsquo; test scores, a student who scored significantly higher or lower than the other students would be considered a univariate outlier.</p><p><img loading=lazy src=images/score_outlier.png#center alt="The red stars indicate the location of the outliers"></p><p>Multivariate outliers, on the other hand, are observations that have extreme values for a combination of variables. These outliers can be more challenging to detect than univariate outliers, as they may not be apparent when examining each variable individually. Multivariate outliers can be identified by using methods such as principal component analysis or cluster analysis. For example, in a dataset of patients&rsquo; medical records, a patient who has a combination of extreme values for several health indicators (such as blood pressure, heart rate, and cholesterol levels) may be considered a multivariate outlier.</p><p><img loading=lazy src=images/patient_outlier.png#center alt="The red stars indicate the location of the outliers"></p><h2 id=how-to-identify-outliers>How to Identify Outliers</h2><p>There are various ways to identify outliers in a dataset using visualization and statistical methods. Here&rsquo;s an example in Python using a toy dataset:</p><p>First, let&rsquo;s import the necessary libraries and create the dataset:</p><pre><code class=language-python>import pandas as pd
import numpy as np
import seaborn as sns
from scipy import stats

# create toy dataset with outliers
data = {'x': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25],
        'y': [8, 6, 9, 7, 15, 6, 7, 10, 12, 6, 7, 8, 9, 6, 7, 8, 100, 12, 10, 6, 7, 8, 9, 6, 7]}
df = pd.DataFrame(data)
</code></pre><h3 id=identifying-outliers-using-visualization>Identifying outliers using visualization</h3><h4 id=1-box-plot>1. Box plot</h4><p>One common way to identify outliers is by using box plots. Box plots provide a visual representation of the distribution of the data, and can highlight observations that are significantly different from the others.</p><pre><code class=language-python># detect outliers using boxplot
sns.boxplot(df)
</code></pre><p><img loading=lazy src=images/boxplot.png#center alt="Box plot"></p><p>From the box plot, we can see that there are some outliers in the <code>y</code> column, but none in the <code>x</code> column.</p><h3 id=2-scatter-plot>2. Scatter plot</h3><p>Another way to identify outliers is by using scatter plots. By plotting the relationship between two variables, scatter plots can effectively illustrate any observations that deviate significantly from the others.</p><pre><code class=language-python># detect outliers using scatterplot
sns.scatterplot(x=df['x'], y=df['y'])
</code></pre><p><img loading=lazy src=images/scatter.png#center alt="Scatter plot"></p><p>From the scatter plot, we can see that there is one observation with <code>x</code> value of 17 and <code>y</code> value of 100 that is significantly different from the others.</p><h3 id=identifying-outliers-using-statistical-methods>Identifying outliers using statistical methods</h3><h4 id=1-interquartile-range-iqr>1. Interquartile range (IQR)</h4><p>The IQR (interquartile range) method is a statistical technique used to identify and handle outliers in a dataset. The IQR is defined as the difference between the third quartile (75th percentile) and the first quartile (25th percentile) of the data.</p><p><img loading=lazy src=images/iqr.png#center alt=IQR></p><p>To use the IQR method to identify outliers, we can follow these steps:</p><ol><li>Calculate the IQR: IQR = Q3 - Q1</li><li>Determine the lower bound: Q1 - 1.5 * IQR</li><li>Determine the upper bound: Q3 + 1.5 * IQR</li><li>Identify the outliers: Any data point that falls outside the lower or upper bound is considered an outlier.</li></ol><p>The IQR method is effective in identifying outliers that are more extreme than those identified by the z-score method. It is less sensitive to extreme values than the z-score method and therefore less likely to flag values as outliers that are actually valid data points. However, it can still misidentify valid data points as outliers if the distribution of the data is highly skewed.</p><pre><code class=language-python># detect outliers using IQR
Q1 = df['y'].quantile(0.25)
Q3 = df['y'].quantile(0.75)
IQR = Q3 - Q1
outliers = df[(df['y'] &lt; Q1 - 1.5 * IQR) | (df['y'] &gt; Q3 + 1.5 * IQR)]
print(outliers)
</code></pre><h4 id=2-z-score>2. Z-score</h4><p>The z-score method is a statistical technique used to identify outliers based on their deviation from the mean. It measures how many standard deviations an observation is away from the mean.</p><p>The formula for calculating the z-score for a particular observation is:</p><p>$$ z = {(x - \mu) \over \sigma} $$</p><p>where <code>x</code> is the value of the observation, <code>μ</code> is the mean of the dataset, and <code>σ</code> is the standard deviation of the dataset.</p><p>If the absolute value of the z-score is greater than a certain threshold, typically 3 or 2.5, then the observation is considered an outlier.</p><pre><code class=language-python># detect outliers using z-score
z_scores = np.abs(stats.zscore(df['y']))
threshold = 3
outliers = df[z_scores &gt; threshold]
print(outliers)
</code></pre><p>The z-score method is widely used in various fields, including finance, economics, and engineering, as it provides a standardized way of identifying extreme values in a dataset. However, it may not always be appropriate to use this method, especially if the dataset is not normally distributed or if there are only a few observations.</p><h2 id=when-should-outliers-be-removed>When Should Outliers Be Removed</h2><p>The decision of whether to remove outliers from a dataset depends on the context and purpose of the analysis. In some cases, outliers may be genuine observations that are important and should not be removed. In other cases, outliers may be errors or anomalies that can distort the analysis and should be removed.</p><p>Here are some general guidelines for when outliers should be removed:</p><p><strong>1. Outliers are errors or anomalies:</strong> If outliers are due to data collection or measurement errors, they should be removed as they do not represent the true population. For example, a weight measurement of 2000 pounds for a human being is an outlier and should be removed because it is physically impossible. Similarly, if data is manually entered and there are typos or errors, those values should be removed.</p><p><strong>2. Outliers are not representative of the population:</strong> Outliers that are not representative of the population being studied may be removed if they skew the distribution or analysis of the data. For instance, if a study is investigating the incomes of middle-class households, an extremely high income that is not representative of the middle class may be removed. Similarly, if a study is investigating the height of adult males, a female value may be an outlier and should be removed. Removing these outliers can help to achieve a more accurate representation of the population.</p><p><strong>3. Outliers significantly affect the results:</strong> Outliers that significantly affect the results of an analysis may be removed if they are deemed to be distorting the data. For example, in regression analysis, outliers can have a disproportionate influence on the regression line and can skew the overall fit of the model. In this case, removing the outliers can help to achieve a more accurate and representative model. However, it is important to note that removing too many outliers can lead to an oversimplification of the model and can lead to the loss of important information.</p><h3 id=takeaways>Takeaways</h3><ul><li>Outliers are values within a dataset that vary greatly from the others, either much larger or significantly smaller, and can be caused by measurement errors, data entry errors, or even legitimate extreme values.</li><li>Outliers can impact machine learning models by distorting the data distribution, affecting the fit of the model, and resulting in inaccurate predictions.</li><li>There are generally two types of outliers: univariate and multivariate. Univariate outliers are observations that have extreme values that relate to just one variable. Multivariate outliers are observations that have extreme values for a combination of variables.</li><li>There are various ways to identify outliers, including visualization (e.g., box plots, scatter plots) and statistical methods (e.g., IQR, z-score).</li><li>The decision of whether to remove outliers from a dataset depends on the context and purpose of the analysis, and outliers should only be removed after careful consideration to ensure that the resulting model accurately represents the population being studied.</li></ul></div><footer class=post-footer><ul class=post-tags><li><a href=https://outlierblog.me/tags/data-cleaning/>data-cleaning</a></li><li><a href=https://outlierblog.me/tags/data-analysis/>data-analysis</a></li></ul><nav class=paginav><a class=prev href=https://outlierblog.me/posts/regularization/><span class=title>« Prev</span><br><span>Understanding Regularization Techniques: L1, L2 and Dropout</span></a>
<a class=next href=https://outlierblog.me/posts/guide_to_tree_method/><span class=title>Next »</span><br><span>A Comprehensive Guide to Tree-Based Methods</span></a></nav><div class=share-buttons><a target=_blank rel="noopener noreferrer" aria-label="share Addressing Outliers For Resilient Machine Learning Models on twitter" href="https://twitter.com/intent/tweet/?text=Addressing%20Outliers%20For%20Resilient%20Machine%20Learning%20Models&url=https%3a%2f%2foutlierblog.me%2fposts%2faddressing_outlier%2f&hashtags=data-cleaning%2cdata-analysis"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM195.519 424.544c135.939.0 210.268-112.643 210.268-210.268.0-3.218.0-6.437-.153-9.502 14.406-10.421 26.973-23.448 36.935-38.314-13.18 5.824-27.433 9.809-42.452 11.648 15.326-9.196 26.973-23.602 32.49-40.92-14.252 8.429-30.038 14.56-46.896 17.931-13.487-14.406-32.644-23.295-53.946-23.295-40.767.0-73.87 33.104-73.87 73.87.0 5.824.613 11.494 1.992 16.858-61.456-3.065-115.862-32.49-152.337-77.241-6.284 10.881-9.962 23.601-9.962 37.088.0 25.594 13.027 48.276 32.95 61.456-12.107-.307-23.448-3.678-33.41-9.196v.92c0 35.862 25.441 65.594 59.311 72.49-6.13 1.686-12.72 2.606-19.464 2.606-4.751.0-9.348-.46-13.946-1.38 9.349 29.426 36.628 50.728 68.965 51.341-25.287 19.771-57.164 31.571-91.8 31.571-5.977.0-11.801-.306-17.625-1.073 32.337 21.15 71.264 33.41 112.95 33.41z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Addressing Outliers For Resilient Machine Learning Models on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&url=https%3a%2f%2foutlierblog.me%2fposts%2faddressing_outlier%2f&title=Addressing%20Outliers%20For%20Resilient%20Machine%20Learning%20Models&summary=Addressing%20Outliers%20For%20Resilient%20Machine%20Learning%20Models&source=https%3a%2f%2foutlierblog.me%2fposts%2faddressing_outlier%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Addressing Outliers For Resilient Machine Learning Models on reddit" href="https://reddit.com/submit?url=https%3a%2f%2foutlierblog.me%2fposts%2faddressing_outlier%2f&title=Addressing%20Outliers%20For%20Resilient%20Machine%20Learning%20Models"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Addressing Outliers For Resilient Machine Learning Models on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2foutlierblog.me%2fposts%2faddressing_outlier%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Addressing Outliers For Resilient Machine Learning Models on whatsapp" href="https://api.whatsapp.com/send?text=Addressing%20Outliers%20For%20Resilient%20Machine%20Learning%20Models%20-%20https%3a%2f%2foutlierblog.me%2fposts%2faddressing_outlier%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Addressing Outliers For Resilient Machine Learning Models on telegram" href="https://telegram.me/share/url?text=Addressing%20Outliers%20For%20Resilient%20Machine%20Learning%20Models&url=https%3a%2f%2foutlierblog.me%2fposts%2faddressing_outlier%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentcolor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></div></footer></article></main><footer class=footer><span>&copy; 2023 <a href=https://outlierblog.me/>Outlier Blog</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(t){t.preventDefault();var e=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(e)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(e)}']`).scrollIntoView({behavior:"smooth"}),e==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${e}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(t=>{const n=t.parentNode.parentNode,e=document.createElement("button");e.classList.add("copy-code"),e.innerHTML="copy";function s(){e.innerHTML="copied!",setTimeout(()=>{e.innerHTML="copy"},2e3)}e.addEventListener("click",o=>{if("clipboard"in navigator){navigator.clipboard.writeText(t.textContent),s();return}const e=document.createRange();e.selectNodeContents(t);const n=window.getSelection();n.removeAllRanges(),n.addRange(e);try{document.execCommand("copy"),s()}catch(e){}n.removeRange(e)}),n.classList.contains("highlight")?n.appendChild(e):n.parentNode.firstChild==n||(t.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?t.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(e):t.parentNode.appendChild(e))})</script></body></html>