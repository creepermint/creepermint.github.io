<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>data-cleaning on Outlier Blog</title>
    <link>https://outlierblog.me/tags/data-cleaning/</link>
    <description>Recent content in data-cleaning on Outlier Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Mon, 29 May 2023 11:30:14 +0800</lastBuildDate><atom:link href="https://outlierblog.me/tags/data-cleaning/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Addressing Outliers For Resilient Machine Learning Models</title>
      <link>https://outlierblog.me/posts/addressing_outlier/</link>
      <pubDate>Mon, 29 May 2023 11:30:14 +0800</pubDate>
      
      <guid>https://outlierblog.me/posts/addressing_outlier/</guid>
      <description>Imagine you’ve spent months collecting and preparing your dataset, carefully selecting features, and building a machine learning model. You’ve fine-tuned the hyperparameters, evaluated the model’s performance, and you’re feeling confident that it’s ready to make accurate predictions on new data. But as soon as you deploy the model, you start to notice some strange results. The model is making bizarre predictions that don’t seem to make sense. What went wrong? The answer may lie in outliers — those pesky data points that can wreak havoc on machine learning models.</description>
    </item>
    
  </channel>
</rss>
